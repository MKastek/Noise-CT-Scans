{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c82ff29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from pydicom import dcmread\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from pydicom import dcmread\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy.interpolate import splrep, splev\n",
    "from scipy.interpolate import CubicSpline\n",
    "from scipy.interpolate import interp1d, RegularGridInterpolator\n",
    "import scipy.optimize as optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e31650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=True, mode='CBR', negative_slope=0.2):\n",
    "    L = []\n",
    "    for t in mode:\n",
    "        if t == 'C':\n",
    "            L.append(nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias))\n",
    "        elif t == 'T':\n",
    "            L.append(nn.ConvTranspose2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias))\n",
    "        elif t == 'B':\n",
    "            L.append(nn.BatchNorm2d(out_channels, momentum=0.9, eps=1e-04, affine=True))\n",
    "        elif t == 'I':\n",
    "            L.append(nn.InstanceNorm2d(out_channels, affine=True))\n",
    "        elif t == 'R':\n",
    "            L.append(nn.ReLU(inplace=True))\n",
    "        elif t == 'r':\n",
    "            L.append(nn.ReLU(inplace=False))\n",
    "        elif t == 'L':\n",
    "            L.append(nn.LeakyReLU(negative_slope=negative_slope, inplace=True))\n",
    "        elif t == 'l':\n",
    "            L.append(nn.LeakyReLU(negative_slope=negative_slope, inplace=False))\n",
    "        elif t == '2':\n",
    "            L.append(nn.PixelShuffle(upscale_factor=2))\n",
    "        elif t == '3':\n",
    "            L.append(nn.PixelShuffle(upscale_factor=3))\n",
    "        elif t == '4':\n",
    "            L.append(nn.PixelShuffle(upscale_factor=4))\n",
    "        elif t == 'U':\n",
    "            L.append(nn.Upsample(scale_factor=2, mode='nearest'))\n",
    "        elif t == 'u':\n",
    "            L.append(nn.Upsample(scale_factor=3, mode='nearest'))\n",
    "        elif t == 'v':\n",
    "            L.append(nn.Upsample(scale_factor=4, mode='nearest'))\n",
    "        elif t == 'M':\n",
    "            L.append(nn.MaxPool2d(kernel_size=kernel_size, stride=stride, padding=0))\n",
    "        elif t == 'A':\n",
    "            L.append(nn.AvgPool2d(kernel_size=kernel_size, stride=stride, padding=0))\n",
    "        else:\n",
    "            raise NotImplementedError('Undefined type: '.format(t))\n",
    "    return sequential(*L)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1701bacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequential(*args):\n",
    "    \"\"\"Advanced nn.Sequential.\n",
    "\n",
    "    Args:\n",
    "        nn.Sequential, nn.Module\n",
    "\n",
    "    Returns:\n",
    "        nn.Sequential\n",
    "    \"\"\"\n",
    "    if len(args) == 1:\n",
    "        if isinstance(args[0], OrderedDict):\n",
    "            raise NotImplementedError('sequential does not support OrderedDict input.')\n",
    "        return args[0]  # No sequential is needed.\n",
    "    modules = []\n",
    "    for module in args:\n",
    "        if isinstance(module, nn.Sequential):\n",
    "            for submodule in module.children():\n",
    "                modules.append(submodule)\n",
    "        elif isinstance(module, nn.Module):\n",
    "            modules.append(module)\n",
    "    return nn.Sequential(*modules)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78929be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_model(model):\n",
    "    if isinstance(model, torch.nn.DataParallel):\n",
    "        model = model.module\n",
    "    msg = '\\n'\n",
    "    msg += 'models name: {}'.format(model.__class__.__name__) + '\\n'\n",
    "    msg += 'Params number: {}'.format(sum(map(lambda x: x.numel(), model.parameters()))) + '\\n'\n",
    "    msg += 'Net structure:\\n{}'.format(str(model)) + '\\n'\n",
    "    return msg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b19e1fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DnCNN(nn.Module):\n",
    "    def __init__(self, in_nc=1, out_nc=1, nc=64, nb=17, act_mode='R'):\n",
    "        \"\"\"\n",
    "        # ------------------------------------\n",
    "        in_nc: channel number of input\n",
    "        out_nc: channel number of output\n",
    "        nc: channel number\n",
    "        nb: total number of conv layers\n",
    "        act_mode: batch norm + activation function; 'BR' means BN+ReLU.\n",
    "        # ------------------------------------\n",
    "        Batch normalization and residual learning are\n",
    "        beneficial to Gaussian denoising (especially\n",
    "        for a single noise level).\n",
    "        The residual of a noisy image corrupted by additive white\n",
    "        Gaussian noise (AWGN) follows a constant\n",
    "        Gaussian distribution which stablizes batch\n",
    "        normalization during training.\n",
    "        # ------------------------------------\n",
    "        \"\"\"\n",
    "        super(DnCNN, self).__init__()\n",
    "        assert 'R' in act_mode or 'L' in act_mode, 'Examples of activation function: R, L, BR, BL, IR, IL'\n",
    "        bias = True\n",
    "        m_head = conv(in_nc, nc, mode='C'+act_mode[-1], bias=bias)\n",
    "        m_body = [conv(nc, nc, mode='C'+act_mode, bias=bias) for _ in range(nb-2)]\n",
    "        m_tail = conv(nc, out_nc, mode='C', bias=bias)\n",
    "\n",
    "        self.model = sequential(m_head, *m_body, m_tail)\n",
    "\n",
    "    def forward(self, x):\n",
    "        n = self.model(x)\n",
    "        return x-n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc9d0171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "models name: DnCNN\n",
      "Params number: 555137\n",
      "Net structure:\n",
      "DnCNN(\n",
      "  (model): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (17): ReLU(inplace=True)\n",
      "    (18): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (19): ReLU(inplace=True)\n",
      "    (20): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (21): ReLU(inplace=True)\n",
      "    (22): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (23): ReLU(inplace=True)\n",
      "    (24): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): ReLU(inplace=True)\n",
      "    (32): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = DnCNN()\n",
    "print(describe_model(model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5d31803",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dncnn_25.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdncnn_25.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\serialization.py:699\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    696\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    697\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 699\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m    701\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m    702\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m    703\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m    704\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\serialization.py:230\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 230\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    232\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\serialization.py:211\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 211\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_open_file, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dncnn_25.pth'"
     ]
    }
   ],
   "source": [
    "torch.load(\"dncnn_25.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3081d52",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dncnn_25.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdncnn_25.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m, strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mnamed_parameters():\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\serialization.py:699\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    696\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    697\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 699\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m    701\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m    702\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m    703\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m    704\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\serialization.py:230\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 230\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    232\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\serialization.py:211\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 211\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_open_file, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dncnn_25.pth'"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.load_state_dict(torch.load(\"dncnn_25.pth\"), strict=True)\n",
    "model.eval()\n",
    "for k, v in model.named_parameters():\n",
    "    v.requires_grad = False\n",
    "model = model.to(device)\n",
    "print('Model path: {:s}'.format(\"dncnn_25.pth\"))\n",
    "number_parameters = sum(map(lambda x: x.numel(), model.parameters()))\n",
    "print('Params number: {}'.format(number_parameters))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28b8a820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DnCNN(\n",
       "  (model): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (21): ReLU(inplace=True)\n",
       "    (22): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (23): ReLU(inplace=True)\n",
       "    (24): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): ReLU(inplace=True)\n",
       "    (32): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f426c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cardio_path = Path().resolve().parents[2] / \"dane\" / \"KARDIO ZAMKNIETE\"\n",
    "data_path = cardio_path / \"A001\" / \"DICOM\" / \"P1\" / \"E1\" / \"S1\" / \"l199\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e32a914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sequence_to_array(data_path: Path):\n",
    "    return np.stack([np.flip(dcmread(file).pixel_array) for file in data_path.iterdir()], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "151be24d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'l199'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m stacked \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_sequence_to_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43ml199\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36mconvert_sequence_to_array\u001b[1;34m(data_path)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_sequence_to_array\u001b[39m(data_path: Path):\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mstack([np\u001b[38;5;241m.\u001b[39mflip(dcmread(file)\u001b[38;5;241m.\u001b[39mpixel_array) \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m data_path\u001b[38;5;241m.\u001b[39miterdir()], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_sequence_to_array\u001b[39m(data_path: Path):\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mstack([np\u001b[38;5;241m.\u001b[39mflip(dcmread(file)\u001b[38;5;241m.\u001b[39mpixel_array) \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m data_path\u001b[38;5;241m.\u001b[39miterdir()], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\pathlib.py:1160\u001b[0m, in \u001b[0;36mPath.iterdir\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21miterdir\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1157\u001b[0m     \u001b[38;5;124;03m\"\"\"Iterate over the files in this directory.  Does not yield any\u001b[39;00m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;124;03m    result for the special paths '.' and '..'.\u001b[39;00m\n\u001b[0;32m   1159\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1160\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1161\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m'\u001b[39m}:\n\u001b[0;32m   1162\u001b[0m             \u001b[38;5;66;03m# Yielding a path object for these makes little sense\u001b[39;00m\n\u001b[0;32m   1163\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'l199'"
     ]
    }
   ],
   "source": [
    "stacked = convert_sequence_to_array(Path()/\"l199\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa72c94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = stacked[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69812d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_NPS_2D(ROI_array, pixel_size_x, pixel_size_y):\n",
    "    NPS_array = []\n",
    "    for roi in ROI_array:\n",
    "        rows, cols = roi.shape\n",
    "        x = np.arange(cols)\n",
    "        y = np.arange(rows)\n",
    "        x, y = np.meshgrid(x, y)\n",
    "        z = np.polyfit(x.ravel(), y.ravel(), 2)\n",
    "        poly_fit = np.polyval(z, x)\n",
    "        # Subtract the polynomial fit from the image\n",
    "        roi = roi - poly_fit\n",
    "        # calculation od DFT 2D\n",
    "        dft = np.fft.fft2(roi - np.mean(roi))\n",
    "        # shift of FT\n",
    "        shifted_dft = np.fft.fftshift(dft)\n",
    "        # calcation of absolute value\n",
    "        NPS_array.append(np.abs(shifted_dft)**2)\n",
    "    N = len(NPS_array)\n",
    "    Ly = NPS_array[0].shape[0]\n",
    "    Lx = NPS_array[0].shape[1]\n",
    "    return (1/N)*(1/(Lx*Ly))*(np.sum(NPS_array,axis=0)*pixel_size_x*pixel_size_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50ebd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_size = 0.402"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dea6556",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_ROI_array_ractangle(image, y0, x0, size, num, plot=False):\n",
    "    r = np.sqrt((y0-256)**2+(x0-256)**2)\n",
    "    ROI_array = []\n",
    "    if plot:\n",
    "        plt.pcolormesh(image)\n",
    "        plt.colorbar();\n",
    "        plt.title(\"Selected ROIs\")\n",
    "    for i in range(num):\n",
    "        y = y0 + size*(i%3)\n",
    "        if(i%3==0):\n",
    "            x = x0 + size*(i//3)\n",
    "        if plot:\n",
    "            plt.gca().add_patch(Rectangle((x-size//2,y-size//2),size,size,\n",
    "                        edgecolor='red',\n",
    "                        facecolor='none',\n",
    "                        lw=1))\n",
    "        ROI_array.append(image[y-size//2:y+size//2,x-size//2:x+size//2])\n",
    "    return ROI_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ea06b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sigma(image, pixel_size):\n",
    "    ROI_array = select_ROI_array_ractangle(image=image, y0=238, x0=432, size=16, num=9)\n",
    "    NPS = calculate_NPS_2D(ROI_array, pixel_size, pixel_size)\n",
    "    dx = 1\n",
    "    dy = 1\n",
    "    return np.sqrt(np.trapz(np.trapz(NPS, dx=dx, axis=1), dx=dy, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105bc89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(image)\n",
    "plt.title(f\"Input image \\n Standard noise {np.std(image):.2f} \\n Noise calculated with NPS: {calculate_sigma(image, pixel_size):.2f}\")\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3c110c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_to_torch(np_array):\n",
    "    \"\"\"\n",
    "    Convert numpy array to torch tensor\n",
    "    \"\"\"\n",
    "    return torch.from_numpy(np_array).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed14be8",
   "metadata": {},
   "outputs": [],
   "source": [
    " np_to_torch(img_noise).reshape(1, 1, 100, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a2ac01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single2tensor4(img):\n",
    "    return torch.from_numpy(img).float().unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d7025b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uint2single(img):\n",
    "    return np.float32(img/255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bd1c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_denoised = model( single2tensor4(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051db950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_to_np(torch_array):\n",
    "    \"\"\"\n",
    "     Convert torch tensor to numpy array\n",
    "     \"\"\"\n",
    "    return np.squeeze(torch_array.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dadadb6",
   "metadata": {},
   "outputs": [],
   "source": [
    " torch_to_np(img_denoised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2b15cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh( torch_to_np(img_denoised))\n",
    "plt.title(f\"Input image \\n Standard noise {np.std(torch_to_np(img_denoised)):.2f} \\n Noise calculated with NPS: {calculate_sigma(torch_to_np(img_denoised), pixel_size):.2f}\")\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caad9182",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_NPS_1D_test(NPS_2D, size_of_pixel_in_spatial_domain):\n",
    "    cen_x = NPS_2D.shape[1]//2\n",
    "    cen_y = NPS_2D.shape[1]//2\n",
    "\n",
    "    # Find radial distances \n",
    "    [X, Y] = np.meshgrid(np.arange(NPS_2D.shape[1])-cen_x, np.arange(NPS_2D.shape[1])-cen_y)\n",
    "    R = np.sqrt(np.square(X)+np.square(Y))\n",
    "\n",
    "    rad = np.arange(0, np.max(R), 1)\n",
    "    intensity = np.zeros(len(rad))\n",
    "    index = 0\n",
    "    bin_size = 1\n",
    "\n",
    "    for i in rad:\n",
    "        mask = (np.greater(R, i - bin_size) & np.less(R, i + bin_size))\n",
    "        rad_values = NPS_2D[mask]\n",
    "        intensity[index] = np.mean(rad_values)\n",
    "        index += 1\n",
    "        # Plot data\n",
    "    x = rad* 1.0 / (size_of_pixel_in_spatial_domain* NPS_2D.shape[1])\n",
    "    y = intensity\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f3f97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plot(x_points, y_points, title, legend, min_x=0, max_x =1.0, num=64):\n",
    "    x_interpolate = np.linspace(min_x , max_x, num)\n",
    "    cubic_spline = CubicSpline(x_points, y_points)\n",
    "    plt.plot(x_points, y_points,'.')\n",
    "    plt.plot(x_interpolate, cubic_spline(x_interpolate),color='blue',label=legend)\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"$f_{r} [mm^{-1}]$\")\n",
    "    plt.xlim(min_x, max_x);\n",
    "    plt.grid(which=\"minor\", alpha=0.3)\n",
    "    plt.grid(which=\"major\", alpha=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186cdd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI_array_rectangle =select_ROI_array_ractangle(image=np.flipud(image[30:130, 250:350]), y0=60, x0=60, size=8, num=9, plot=True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "NPS_2D_rectangle = calculate_NPS_2D(ROI_array_rectangle, pixel_size, pixel_size)\n",
    "rad_1, intensity_1 = calculate_NPS_1D_test(NPS_2D_rectangle,pixel_size)\n",
    "make_plot(rad_1, intensity_1, title=\"CT Scan - rectangle ROI of orignal image\", legend = \" NPS 1D\", min_x=0, max_x =1.0, num=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23432912",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI_array_rectangle =select_ROI_array_ractangle(image=np.flipud(torch_to_np(img_denoised)[30:130, 250:350]), y0=60, x0=60, size=8, num=9, plot=True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "NPS_2D_rectangle = calculate_NPS_2D(ROI_array_rectangle, pixel_size, pixel_size)\n",
    "rad_1, intensity_1 = calculate_NPS_1D_test(NPS_2D_rectangle,pixel_size)\n",
    "make_plot(rad_1, intensity_1, title=\"CT Scan - rectangle ROI of orignal image\", legend = \" NPS 1D\", min_x=0, max_x =1.0, num=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83743eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(image-torch_to_np(img_denoised))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "871ef725",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m path \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m      2\u001b[0m     Path()\u001b[38;5;241m.\u001b[39mresolve()\u001b[38;5;241m.\u001b[39mparents[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdane\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mS1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     10\u001b[0m )\n\u001b[1;32m---> 11\u001b[0m images \u001b[38;5;241m=\u001b[39m \u001b[43mget_data\u001b[49m(path)\n\u001b[0;32m     12\u001b[0m model \u001b[38;5;241m=\u001b[39m PDnCNN()\n\u001b[0;32m     13\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmarci\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mICM\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mMGR\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mprogramy\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mNoise-CT-Scans\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdncnn_25.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m), strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_data' is not defined"
     ]
    }
   ],
   "source": [
    "path = (\n",
    "    Path().resolve().parents[2]\n",
    "    / \"dane\"\n",
    "    / \"KARDIO ZAMKNIETE\"\n",
    "    / \"A001\"\n",
    "    / \"DICOM\"\n",
    "    / \"P1\"\n",
    "    / \"E1\"\n",
    "    / \"S1\"\n",
    ")\n",
    "images = get_data(path)\n",
    "model = PDnCNN()\n",
    "model.load_state_dict(torch.load(r\"C:\\Users\\marci\\Desktop\\ICM\\MGR\\programy\\Noise-CT-Scans\\train\\dncnn_25.pth\"), strict=True)\n",
    "model.eval()\n",
    "for k, v in model.named_parameters():\n",
    "    v.requires_grad = False\n",
    "\n",
    "y = model(torch.from_numpy(images[200]).float().unsqueeze(0))\n",
    "\n",
    "make_dot(y.mean(), params=dict(model.named_parameters()),  show_attrs=True, show_saved=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cd4f5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
